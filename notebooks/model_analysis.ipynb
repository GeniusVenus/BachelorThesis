{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T16:27:20.788504Z",
     "start_time": "2025-06-03T16:27:20.777419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from src.models import SegmentationModel\n",
    "from src.utils.config import load_config"
   ],
   "id": "a6126aa9cd65802b",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T16:27:20.819174Z",
     "start_time": "2025-06-03T16:27:20.796137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config = load_config('../configs/models/upernet.yml')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "id": "ed42b9e07a3d4179",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T16:27:22.454528Z",
     "start_time": "2025-06-03T16:27:20.836218Z"
    }
   },
   "cell_type": "code",
   "source": "model = SegmentationModel.get_model(config['model']['name'], **config['model'].get('params', {})).to(device)",
   "id": "43346cd11dbced2a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of UperNetForSemanticSegmentation were not initialized from the model checkpoint at openmmlab/upernet-convnext-tiny and are newly initialized because the shapes did not match:\n",
      "- auxiliary_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "- auxiliary_head.classifier.weight: found shape torch.Size([150, 256, 1, 1]) in the checkpoint and torch.Size([5, 256, 1, 1]) in the model instantiated\n",
      "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "- decode_head.classifier.weight: found shape torch.Size([150, 512, 1, 1]) in the checkpoint and torch.Size([5, 512, 1, 1]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T16:27:22.485318Z",
     "start_time": "2025-06-03T16:27:22.472562Z"
    }
   },
   "cell_type": "code",
   "source": "print(sum(p.numel() for p in model.parameters()))",
   "id": "19a9566f7a10b4d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60130986\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T16:27:22.515715Z",
     "start_time": "2025-06-03T16:27:22.502435Z"
    }
   },
   "cell_type": "code",
   "source": "print(sum(p.numel() for p in model.parameters() if p.requires_grad))",
   "id": "64796eec9752f1ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60130986\n"
     ]
    }
   ],
   "execution_count": 35
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
